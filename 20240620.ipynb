{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "493ac30c-2903-4f70-b1d5-92ccfbe5ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc0bbd39-4446-43c0-b709-6d226ba281cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/20 03:37:00 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CSV Reader\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"file:///home/hadoop/jupyter/dataengineering/dataset/retail-data/by-day/*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02025600-af15-4a08-a0b3-405cc1537e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|       Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   580538|    23084|RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|\n",
      "+---------+---------+------------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22a9bb1-78c2-436e-801a-628d2a953eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "531694"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6dc2bc3-261d-48b0-a5c4-8596569070c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"dTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e33f1b8-eb79-471b-8726-3b5ed794c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b785d41b-8626-404e-b5a0-884a904acc63",
   "metadata": {},
   "source": [
    "## 문제 1\n",
    "### InvoiceNo가 536365 row 값에서 InvoiceNo, Description만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6d31a77-74bc-42bf-bf4c-7edccb28ce77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:===================>                                      (2 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|InvoiceNo|         Description|\n",
      "+---------+--------------------+\n",
      "|   536365|WHITE HANGING HEA...|\n",
      "|   536365| WHITE METAL LANTERN|\n",
      "|   536365|CREAM CUPID HEART...|\n",
      "|   536365|KNITTED UNION FLA...|\n",
      "|   536365|RED WOOLLY HOTTIE...|\n",
      "|   536365|SET 7 BABUSHKA NE...|\n",
      "|   536365|GLASS STAR FROSTE...|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.filter(df.InvoiceNo == \"536365\").\\\n",
    "    select(df.InvoiceNo, df.Description).\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec4fe7c1-e82c-4076-b0f0-463b3dff1b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|InvoiceNo|         Description|\n",
      "+---------+--------------------+\n",
      "|   536365|WHITE HANGING HEA...|\n",
      "|   536365| WHITE METAL LANTERN|\n",
      "|   536365|CREAM CUPID HEART...|\n",
      "|   536365|KNITTED UNION FLA...|\n",
      "|   536365|RED WOOLLY HOTTIE...|\n",
      "|   536365|SET 7 BABUSHKA NE...|\n",
      "|   536365|GLASS STAR FROSTE...|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df.where(expr(\"InvoiceNo == 536365\")).\\\n",
    "    select(\"InvoiceNo\", \"Description\").\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efd2d4e0-a559-42b3-93ad-6258fffc73e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import instr, col\n",
    "\n",
    "filter_ = col(\"UnitPrice\") > 600\n",
    "filter_2 = instr(df.Description, \"POSTAGE\") >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9a8040f-fdef-4fef-899a-c3e6221d7a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|       Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   580538|    23084|RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|\n",
      "+---------+---------+------------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61923404-46dd-4d28-8e40-e63967606885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|   580610|      DOT|DOTCOM POSTAGE|       1|2011-12-05 11:48:00|  2196.67|      null|United Kingdom|\n",
      "|   580612|      DOT|DOTCOM POSTAGE|       1|2011-12-05 11:58:00|   2114.0|      null|United Kingdom|\n",
      "|   580727|      DOT|DOTCOM POSTAGE|       1|2011-12-05 17:17:00|  1599.26|   14096.0|United Kingdom|\n",
      "|   580729|      DOT|DOTCOM POSTAGE|       1|2011-12-05 17:24:00|   1172.1|      null|United Kingdom|\n",
      "|   580730|      DOT|DOTCOM POSTAGE|       1|2011-12-05 17:28:00|   845.23|      null|United Kingdom|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.StockCode.isin(\"DOT\")).\\\n",
    "    where(filter_ | filter_2).\\\n",
    "    limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6a3de9-1c1a-461f-8503-b4134e3ea51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"\"\"\n",
    "    select * from dTable limit 3\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54bc6204-0903-4ee2-a34a-98c5875303c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   580538|    23084|  RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|\n",
      "|   580538|    23077| DOUGHNUT LIP GLOSS |      20|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "|   580538|    22906|12 MESSAGE CARDS ...|      24|2011-12-05 08:38:00|     1.65|   14075.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8011b80f-d99e-4448-8f77-0bb8f14b3bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "      select *\n",
    "      from dTable\n",
    "      where StockCode in (\"DOT\")\n",
    "      AND (UnitPrice > 600 OR\n",
    "      instr(Description, \"PostAGE\") >= 1) limit 5;\n",
    "      \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b53c9815-2f37-40ce-9af6-b84be247f07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|   580610|      DOT|DOTCOM POSTAGE|       1|2011-12-05 11:48:00|  2196.67|      null|United Kingdom|\n",
      "|   580612|      DOT|DOTCOM POSTAGE|       1|2011-12-05 11:58:00|   2114.0|      null|United Kingdom|\n",
      "|   580727|      DOT|DOTCOM POSTAGE|       1|2011-12-05 17:17:00|  1599.26|   14096.0|United Kingdom|\n",
      "|   580729|      DOT|DOTCOM POSTAGE|       1|2011-12-05 17:24:00|   1172.1|      null|United Kingdom|\n",
      "|   580730|      DOT|DOTCOM POSTAGE|       1|2011-12-05 17:28:00|   845.23|      null|United Kingdom|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6bb44c7-d7e5-4671-bc50-c8d12781a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, instr\n",
    "filter_1 = col(\"StockCode\") == \"DOT\"\n",
    "filter_2 = col(\"UnitPrice\") > 600\n",
    "filter_3 = instr(col(\"Description\"), \"POSTAGE\") >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3a657a2-3635-451b-9cbc-c3e99262e320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|unitPrice|isExpensive|\n",
      "+---------+-----------+\n",
      "|  2196.67|       true|\n",
      "|   2114.0|       true|\n",
      "|  1599.26|       true|\n",
      "|   1172.1|       true|\n",
      "|   845.23|       true|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"isExpensive\", filter_1 & (filter_2 | filter_3)).\\\n",
    "    where(\"isExpensive\").\\\n",
    "    select(\"unitPrice\", \"isExpensive\").limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23b44f8e-2af4-4ecf-af02-e13f2d3a5265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|UnitPrice|isExpensive|\n",
      "+---------+-----------+\n",
      "|  2196.67|       true|\n",
      "|   2114.0|       true|\n",
      "|  1599.26|       true|\n",
      "|   1172.1|       true|\n",
      "|   845.23|       true|\n",
      "|    863.8|       true|\n",
      "|  1008.96|       true|\n",
      "|  1683.75|       true|\n",
      "|   938.59|       true|\n",
      "|   1563.0|       true|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "        select UnitPrice, StockCode = \"DOT\"\n",
    "        AND (UnitPrice > 600 OR instr(Description, \"POSTAGE\") >= 1) as isExpensive\n",
    "        from dTable\n",
    "        where StockCode = \"DOT\"\n",
    "        AND (UnitPrice > 600 OR instr(Description, \"POSTAGE\") >= 1) limit 10;\n",
    "      \"\"\"\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2813218-6fab-4ee3-a81f-84b4386aa4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, pow, col\n",
    "# (현재 수량 * 단가) ^2 + 5\n",
    "condition1 = pow(col(\"Quantity\") * col(\"UnitPrice\"), 2) + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80ae253f-a3fe-4be9-8f92-860c36ffbe1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerId|      realQuantity|\n",
      "+----------+------------------+\n",
      "|   14075.0|         7387.2464|\n",
      "|   14075.0|             630.0|\n",
      "|   14075.0|1573.1599999999996|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"CustomerId\"), condition1.alias(\"realQuantity\")   ).limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "454acc29-eb66-41b4-a507-ed0dc01b1894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------------------------+\n",
      "|CustomerId|(POWER((Quantity * UnitPrice), 2) + 5)|\n",
      "+----------+--------------------------------------+\n",
      "|   14075.0|                             7387.2464|\n",
      "|   14075.0|                                 630.0|\n",
      "|   14075.0|                    1573.1599999999996|\n",
      "|   14075.0|                                 905.0|\n",
      "|   14075.0|                    239.08999999999997|\n",
      "|   14075.0|                    1669.6399999999999|\n",
      "|   14075.0|                               1573.16|\n",
      "|   14075.0|                    1650.1136000000001|\n",
      "|   18180.0|                                 294.0|\n",
      "|   18180.0|                                 294.0|\n",
      "+----------+--------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = \\\n",
    "    \"\"\"\n",
    "    select CustomerId, POWER((Quantity *UnitPrice), 2) + 5\n",
    "    from dTable limit 10\n",
    "    \"\"\"\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c3df5b0-c14f-49f7-8bf6-ce9b3777fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round, bround, ceil, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f9fd6527-4cf4-42ec-bfe0-5021359e9586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-------------+--------------+------------+----------+\n",
      "| name| value|rounded_value|constant_value|bround_value|ceil_value|\n",
      "+-----+------+-------------+--------------+------------+----------+\n",
      "|Alice|  23.5|         23.5|          23.5|        23.5|        24|\n",
      "|  Bob|34.234|         34.2|          34.2|        34.2|        35|\n",
      "|Cathy|45.789|         45.8|          45.8|        45.8|        46|\n",
      "+-----+------+-------------+--------------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예제 데이터 생성\n",
    "data = [\n",
    "    (\"Alice\", 23.5),\n",
    "    (\"Bob\", 34.234),\n",
    "    (\"Cathy\", 45.789)\n",
    "]\n",
    "\n",
    "# 스키마 정의\n",
    "columns = [\"name\", \"value\"]\n",
    "\n",
    "# DataFrame 생성\n",
    "df_ex = spark.createDataFrame(data, schema=columns)\n",
    "\n",
    "\n",
    "# round와 lit 사용\n",
    "df_ex = df_ex.withColumn(\"rounded_value\", round(\"value\", 1)) \\\n",
    "       .withColumn(\"constant_value\", lit(round(\"value\", 1))) \\\n",
    "       .withColumn(\"bround_value\", bround(\"value\", 1)) \\\n",
    "       .withColumn(\"ceil_value\", ceil(\"value\"))\n",
    "\n",
    "# 결과 출력\n",
    "df_ex.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "180a76df-ab1c-494b-a794-9ac01f987f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/20 02:40:26 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 48:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+-----------+--------+---------+----------+-------+\n",
      "|summary|InvoiceNo|StockCode|Description|Quantity|UnitPrice|CustomerID|Country|\n",
      "+-------+---------+---------+-----------+--------+---------+----------+-------+\n",
      "|  count|   531694|   531694|     530257|  531694|   531694|    401575| 531694|\n",
      "+-------+---------+---------+-----------+--------+---------+----------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('*').describe().limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d3f21b2a-c169-4892-a494-a66c12989a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, mean, stddev_pop, min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e5f6a8df-e8ea-4cc3-bdc0-866c90430ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:=============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+---------------------+--------------+--------------+\n",
      "|   avg(UnitPrice)|count(UnitPrice)|stddev_pop(UnitPrice)|min(UnitPrice)|max(UnitPrice)|\n",
      "+-----------------+----------------+---------------------+--------------+--------------+\n",
      "|4.616183771117624|          531694|    97.64335099564296|     -11062.06|       38970.0|\n",
      "+-----------------+----------------+---------------------+--------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(mean(\"UnitPrice\"), count(\"UnitPrice\"),stddev_pop(\"UnitPrice\"), min(\"UnitPrice\"), max(\"UnitPrice\")).limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5f4e4ac2-fa7c-41bb-a78e-9edbc505aad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 62:=======================>                                  (2 + 2) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|    Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+---------------+--------+-------------------+---------+----------+--------------+\n",
      "|  A563186|        B|Adjust bad debt|       1|2011-08-12 14:51:00|-11062.06|      null|United Kingdom|\n",
      "|  A563187|        B|Adjust bad debt|       1|2011-08-12 14:52:00|-11062.06|      null|United Kingdom|\n",
      "+---------+---------+---------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "min_price = df.agg(min(\"UnitPrice\")).first()[0]\n",
    "df.filter(col(\"UnitPrice\") == min_price).limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "82705180-6c02-4bc7-be2e-5efdd7d4e949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.08]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stat.approxQuantile(\"UnitPrice\", [0.5], 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc28c1a-980f-4a86-a9fd-7a706060fec8",
   "metadata": {},
   "source": [
    "### \"UnitPrice\": UnitPrice 컬럼에서 백분위수를 계산합니다.\n",
    "#### [0.5]: 계산할 백분위수를 나타내는 리스트입니다. 여기서는 0.5 백분위수, 즉 중앙값(median)을 계산합니다.\n",
    "#### 0.05: 상대적인 오차입니다. 이 값은 결과값이 실제 백분위수의 ±5% 내에 있음을 보장합니다. 이 값이 작을수록 계산은 더 정확하지만, 더 많은 계산 비용이 듭니다.\n",
    "#### 즉, 이 코드의 목적은 UnitPrice 컬럼의 중앙값을 근사적으로 계산하는 것입니다. 중앙값은 데이터셋에서 중간에 위치하는 값으로, 데이터를 반으로 나누는 값입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4954651c-890f-442e-af3a-73d3036e189e",
   "metadata": {},
   "source": [
    "# 문자열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "40b34608-e29b-43c7-b773-b285aaeb0cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import initcap, col, lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "947ff635-3182-433e-ac96-a1441708a5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function initcap in module pyspark.sql.functions:\n",
      "\n",
      "initcap(col: 'ColumnOrName') -> pyspark.sql.column.Column\n",
      "    Translate the first letter of each word to upper case in the sentence.\n",
      "\n",
      "    .. versionadded:: 1.5.0\n",
      "\n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    col : :class:`~pyspark.sql.Column` or str\n",
      "        target column to work on.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    :class:`~pyspark.sql.Column`\n",
      "        string with all first letters are uppercase in each word.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> spark.createDataFrame([('ab cd',)], ['a']).select(initcap(\"a\").alias('v')).collect()\n",
      "    [Row(v='Ab Cd')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(initcap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cc12c6ae-b28c-4505-bf26-8c24eeb40d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|         Description|  upper(Description)|initcap(Description)|  lower(Description)|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|  RABBIT NIGHT LIGHT|  RABBIT NIGHT LIGHT|  Rabbit Night Light|  rabbit night light|\n",
      "| DOUGHNUT LIP GLOSS | DOUGHNUT LIP GLOSS | Doughnut Lip Gloss | doughnut lip gloss |\n",
      "|12 MESSAGE CARDS ...|12 MESSAGE CARDS ...|12 Message Cards ...|12 message cards ...|\n",
      "|BLUE HARMONICA IN...|BLUE HARMONICA IN...|Blue Harmonica In...|blue harmonica in...|\n",
      "|   GUMBALL COAT RACK|   GUMBALL COAT RACK|   Gumball Coat Rack|   gumball coat rack|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Description\", upper(\"Description\"), initcap(\"Description\"), lower(\"Description\")).limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2aaf2a70-7665-4e10-bc09-4b07e74b3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, ltrim, rtrim, rpad, lpad, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f7e84ebe-d0ea-41d3-ae4a-994f09b62868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------------+--------------+----------------+\n",
      "|ltrim(  Hi    )|rtrim(     Hi     )|trim(     Hi    )|rpad(Hi, 10, )|lpad(   Hi, 6, )|\n",
      "+---------------+-------------------+-----------------+--------------+----------------+\n",
      "|         Hi    |                 Hi|               Hi|            Hi|              Hi|\n",
      "|         Hi    |                 Hi|               Hi|            Hi|              Hi|\n",
      "|         Hi    |                 Hi|               Hi|            Hi|              Hi|\n",
      "+---------------+-------------------+-----------------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(ltrim(lit(\"  Hi    \")), \n",
    "          rtrim(lit(\"     Hi     \")), \n",
    "          trim(lit(\"     Hi    \")),\n",
    "          rpad(lit(\"Hi\"), 10, \"\"),\n",
    "          lpad(lit(\"   Hi\"), 6, \"\")).limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "282f34ed-78ee-4546-8bfa-e3176cb6ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, regexp_extract, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6d74ed5-4357-41f2-9648-6027e50ccb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_string = \"BLACK|WHITE|RED|GREEN|BLUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e21ee64-ebf1-44a2-8491-ba2589687eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select( regexp_replace(col(\"Description\"), regex_string, \"COLOR\").alias(\"color\"),\n",
    "            col(\"Description\")).limit(10).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80791c34-2a28-4a47-8a24-3d89577eb270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+-----------------------------------+\n",
      "|color                              |Description                        |\n",
      "+-----------------------------------+-----------------------------------+\n",
      "|RABBIT NIGHT LIGHT                 |RABBIT NIGHT LIGHT                 |\n",
      "|DOUGHNUT LIP GLOSS                 |DOUGHNUT LIP GLOSS                 |\n",
      "|12 MESSAGE CARDS WITH ENVELOPES    |12 MESSAGE CARDS WITH ENVELOPES    |\n",
      "|color HARMONICA IN BOX             |BLUE HARMONICA IN BOX              |\n",
      "|GUMBALL COAT RACK                  |GUMBALL COAT RACK                  |\n",
      "|SKULLS  WATER TRANSFER TATTOOS     |SKULLS  WATER TRANSFER TATTOOS     |\n",
      "|FELTCRAFT GIRL AMELIE KIT          |FELTCRAFT GIRL AMELIE KIT          |\n",
      "|CAMOUFLAGE LED TORCH               |CAMOUFLAGE LED TORCH               |\n",
      "|color SKULL HOT WATER BOTTLE       |WHITE SKULL HOT WATER BOTTLE       |\n",
      "|ENGLISH ROSE HOT WATER BOTTLE      |ENGLISH ROSE HOT WATER BOTTLE      |\n",
      "|HOT WATER BOTTLE KEEP CALM         |HOT WATER BOTTLE KEEP CALM         |\n",
      "|SCOTTIE DOG HOT WATER BOTTLE       |SCOTTIE DOG HOT WATER BOTTLE       |\n",
      "|ROSE CARAVAN DOORSTOP              |ROSE CARAVAN DOORSTOP              |\n",
      "|GINGHAM HEART  DOORSTOP color      |GINGHAM HEART  DOORSTOP RED        |\n",
      "|STORAGE TIN VINTAGE LEAF           |STORAGE TIN VINTAGE LEAF           |\n",
      "|SET OF 4 KNICK KNACK TINS POPPIES  |SET OF 4 KNICK KNACK TINS POPPIES  |\n",
      "|POPCORN HOLDER                     |POPCORN HOLDER                     |\n",
      "|GROW A FLYTRAP OR SUNFLOWER IN TIN |GROW A FLYTRAP OR SUNFLOWER IN TIN |\n",
      "|AIRLINE BAG VINTAGE WORLD CHAMPION |AIRLINE BAG VINTAGE WORLD CHAMPION |\n",
      "|AIRLINE BAG VINTAGE JET SET BROWN  |AIRLINE BAG VINTAGE JET SET BROWN  |\n",
      "+-----------------------------------+-----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select regexp_replace(Description, \"BLACK|WHITE|RED|GREEN|BLUE\", \"color\")\n",
    "    as color, Description from dTable\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14eed588-6405-47f0-8396-40466d5b8f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------+\n",
      "|color|Description                    |\n",
      "+-----+-------------------------------+\n",
      "|     |RABBIT NIGHT LIGHT             |\n",
      "|     |DOUGHNUT LIP GLOSS             |\n",
      "|     |12 MESSAGE CARDS WITH ENVELOPES|\n",
      "|BLUE |BLUE HARMONICA IN BOX          |\n",
      "|     |GUMBALL COAT RACK              |\n",
      "|     |SKULLS  WATER TRANSFER TATTOOS |\n",
      "|     |FELTCRAFT GIRL AMELIE KIT      |\n",
      "|     |CAMOUFLAGE LED TORCH           |\n",
      "|WHITE|WHITE SKULL HOT WATER BOTTLE   |\n",
      "|     |ENGLISH ROSE HOT WATER BOTTLE  |\n",
      "+-----+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select( regexp_extract(col(\"Description\"), regex_string, 0).alias(\"color\"),\n",
    "            col(\"Description\")).limit(10).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c541b53-c48d-4c35-a60c-58b3eba8428b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72bd5f0-52f7-4dd8-9467-b6cb9e9f5d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57cfa09-a028-48b5-8a17-90b4499ef7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371ba03f-542b-4e2b-b0c9-9baedbef38e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04294e7d-be36-4508-8154-7af2e0e51c85",
   "metadata": {},
   "source": [
    "## mysql 에서 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf5e0aef-5788-4b3b-a0ca-4955d1031d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "encore = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "    .option(\"url\", \"jdbc:mysql://43.202.5.70:3306/encore_web\") \\\n",
    "    .option(\"dbtable\",\"encore_question\") \\\n",
    "    .option(\"numPartitions\",5) \\\n",
    "    .option(\"user\", \"class5\") \\\n",
    "    .option(\"password\", 'EnCoRo!23') \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6714313b-a1e1-442b-bcd2-c448bd212e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+--------------------+---------+\n",
      "| id|subject|content|         create_date|quthor_id|\n",
      "+---+-------+-------+--------------------+---------+\n",
      "|140|  점_심|   점심|2024-06-20 02:13:...|       50|\n",
      "+---+-------+-------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import instr\n",
    "encore.where(instr(\"content\", \"점심\")>=1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b27e166-e1c2-4e2a-be6a-3f36ef90b907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, pow, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf8bfe58-ecec-452c-8d61-ec6ea39937f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(POWER((Quantity * UnitPrice), 2) + 5)'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (현재 수량 * 단가) ^2 + 5\n",
    "pow(col(\"Quantity\") * col(\"UnitPrice\"), 2) + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9501f8cc-8d19-48e0-9ae9-4aa37636063a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
