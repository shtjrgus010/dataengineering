{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5195be-82ec-4c73-8133-c815e2f83e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 00:20:30,885 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pyarrow import fs\n",
    "import pyarrow as pa\n",
    "\n",
    "classpath = subprocess.Popen([\"/home/hadoop/hadoop/bin/hdfs\", \"classpath\", \"--glob\"], stdout=subprocess.PIPE).communicate()[0]\n",
    "os.environ[\"CLASSPATH\"] = classpath.decode(\"utf-8\")\n",
    "hdfs = fs.HadoopFileSystem(host='192.168.0.160', port=8020, user='hadoop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662734f6-fb50-4f4c-8f97-5c9f154014d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/1111111\n",
      "/20240619\n",
      "/20280619\n",
      "/2chung1\n",
      "/awannagohome\n",
      "/bobb\n",
      "/bsh\n",
      "/chy\n",
      "/class5-0617\n",
      "/class5_0617\n",
      "/cma\n",
      "/cmh\n",
      "/cts\n",
      "/dob\n",
      "/dragonair\n",
      "/encore\n",
      "/gohome\n",
      "/hazy\n",
      "/hungry\n",
      "/jeong\n",
      "/jeong_0614\n",
      "/jotaesik\n",
      "/kdg\n",
      "/kdh\n",
      "/khj\n",
      "/kkh\n",
      "/kkh5\n",
      "/kkk\n",
      "/kse\n",
      "/ksj\n",
      "/leshen\n",
      "/lhe\n",
      "/lllIlll\n",
      "/ma0619\n",
      "/mama\n",
      "/mort\n",
      "/mort_0617\n",
      "/mort_20240619\n",
      "/mydata\n",
      "/naverNews\n",
      "/psw\n",
      "/rsh\n",
      "/scw\n",
      "/ssy\n",
      "/stock\n",
      "/test2\n",
      "/tmp\n",
      "/user\n",
      "/wannagohome\n",
      "/yjy\n",
      "/yjy_test.parquet\n",
      "/ys\n",
      "/yssw\n"
     ]
    }
   ],
   "source": [
    "# 디렉토리 경로\n",
    "dir_path = '/'\n",
    "\n",
    "# 디렉토리 목록 가져오기\n",
    "file_infos = hdfs.get_file_info(pa.fs.FileSelector(dir_path, recursive=False))  \n",
    "for file_info in file_infos:\n",
    "    print(file_info.path) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c6500ad-1fd0-456a-b275-94459c3c22cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark.stop()\n",
    "spark = SparkSession.builder.appName(\"www\").getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"hdfs:////encore/tpss_bcycl_od_statnhm_202001.csv\", encoding='cp949', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e38bd94-ee0d-4ac9-bcf7-dac1a6a3ec9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://producer:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>www</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd21bb24860>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4abec1d4-4cc6-47ac-bfe8-348c8910e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"James\", \"Sales\", 3000), \\\n",
    "    (\"Michael\", \"Sales\", 4600), \\\n",
    "    (\"Robert\", \"Sales\", 4100), \\\n",
    "    (\"Maria\", \"Finance\", 3000), \\\n",
    "    (\"James\", \"Sales\", 3000), \\\n",
    "    (\"Scott\", \"Finance\", 3300), \\\n",
    "    (\"Jen\", \"Finance\", 3900), \\\n",
    "    (\"Jeff\", \"Marketing\", 3000), \\\n",
    "    (\"Kumar\", \"Marketing\", 2000), \\\n",
    "    (\"Saif\", \"Sales\", 4100) \\\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bcec561-420e-43a2-94bd-dc7bcf8e4005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "columns= [\"employee_name\", \"department\", \"salary\"]\n",
    "test = spark.createDataFrame(data = data, schema = columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52a5ac48-fcf7-4900-ad51-3c44ad148c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1543"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"시작_대여소ID\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31a0fcb5-71eb-48b8-a75c-92bcbcc88642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(기준_날짜='20200101', 구분코드='0', 기준_시간='0000', 시작_대여소ID='ST-443', 시작_대여소명='성산2동_041_2', 종료_대여소ID='ST-82', 종료_대여소명='성산2동_041_3', 전체건수='1', 전체이용시간(분)='2', 전체이용거리(m)='450')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e37740f2-c309-4be1-959c-99facec2f252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 기준_날짜: string (nullable = true)\n",
      " |-- 구분코드: string (nullable = true)\n",
      " |-- 기준_시간: string (nullable = true)\n",
      " |-- 시작_대여소ID: string (nullable = true)\n",
      " |-- 시작_대여소명: string (nullable = true)\n",
      " |-- 종료_대여소ID: string (nullable = true)\n",
      " |-- 종료_대여소명: string (nullable = true)\n",
      " |-- 전체건수: string (nullable = true)\n",
      " |-- 전체이용시간(분): string (nullable = true)\n",
      " |-- 전체이용거리(m): string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b8e7144-c1e3-4ff7-ad6b-ab72f8b958a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형변환\n",
    "from pyspark.sql.functions import  col\n",
    "df2 = df.withColumn(\"전체이용거리(m)\", col(\"전체이용거리(m)\").cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf2985a9-c0aa-4c0f-b4f6-791aebd5a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "df3 = df.withColumn(\"전체 이용거리(m)\", col(\"전체이용거리(m)\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5633928-005f-42b1-97f6-bb2b9ec9e322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------+-------------+----------------+-------------+----------------+--------+----------------+---------------+----------------+\n",
      "|기준_날짜|구분코드|기준_시간|시작_대여소ID|   시작_대여소명|종료_대여소ID|   종료_대여소명|전체건수|전체이용시간(분)|전체이용거리(m)|전체 이용거리(m)|\n",
      "+---------+--------+---------+-------------+----------------+-------------+----------------+--------+----------------+---------------+----------------+\n",
      "| 20200101|       0|     0000|       ST-443|   성산2동_041_2|        ST-82|   성산2동_041_3|       1|               2|            450|             450|\n",
      "| 20200101|       0|     0000|        ST-56|   여의동_005_10|      ST-1321|  영등포동_036_1|       1|              10|           1460|            1460|\n",
      "| 20200101|       0|     0000|      ST-1546|    조원동_004_1|       ST-703|    신사동_023_1|       1|               5|            700|             700|\n",
      "| 20200101|       1|     0000|      ST-1701|   당산2동_065_1|      ST-1701|   당산2동_065_1|       1|              28|          70670|           70670|\n",
      "| 20200101|       1|     0000|      ST-1390|   수유2동_030_1|      ST-1101|    미아동_010_1|       1|              14|          59030|           59030|\n",
      "| 20200101|       1|     0000|      ST-1128|   하계1동_008_1|      ST-1473|  중계본동_032_1|       1|              11|           1170|            1170|\n",
      "| 20200101|       0|     0000|        ST-26|    대흥동_015_1|       ST-202|    공덕동_076_1|       1|              11|           1670|            1670|\n",
      "| 20200101|       1|     0000|       ST-118|    사직동_004_1|       ST-978|청운효자동_023_1|       1|              98|           1160|            1160|\n",
      "| 20200101|       1|     0000|       ST-517|    염창동_009_1|      ST-1509|   가양3동_015_1|       1|               4|           1180|            1180|\n",
      "| 20200101|       1|     0000|        ST-31|    대흥동_005_2|       ST-207|    대흥동_016_1|       1|               3|            390|             390|\n",
      "| 20200101|       0|     0000|      ST-1377|    사근동_007_1|       ST-243|    용답동_003_1|       1|               7|           1710|            1710|\n",
      "| 20200101|       1|     0000|      ST-1464|   방학1동_008_1|      ST-1726|   쌍문1동_040_1|       1|              28|           3680|            3680|\n",
      "| 20200101|       1|     0000|       ST-611|상계6・7동_029_2|      ST-1124|   상계2동_039_1|       1|               1|            350|             350|\n",
      "| 20200101|       1|     0000|        ST-77|    상암동_001_2|        ST-84|    상암동_025_7|       1|              10|           1200|            1200|\n",
      "| 20200101|       1|     0000|      ST-1425|  중계본동_007_1|      ST-1425|  중계본동_007_1|       1|              39|              0|               0|\n",
      "| 20200101|       0|     0000|      ST-1691|    대흥동_021_1|        ST-28|    대흥동_007_2|       1|               2|              0|               0|\n",
      "| 20200101|       0|     0000|      ST-1723|   월곡1동_019_1|      ST-1633|   길음2동_004_1|       1|               6|           1210|            1210|\n",
      "| 20200101|       1|     0000|      ST-1560|   개포2동_030_3|       ST-803|   대치1동_024_1|       1|               5|           1620|            1620|\n",
      "| 20200101|       1|     0000|        ST-73|    여의동_009_1|        ST-73|    여의동_009_1|       1|              24|              0|               0|\n",
      "| 20200101|       1|     0000|       ST-663|  신도림동_008_1|      ST-1733|  신도림동_033_1|       1|               1|            430|             430|\n",
      "+---------+--------+---------+-------------+----------------+-------------+----------------+--------+----------------+---------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a0ca834-608d-4883-8279-a174f5e7d4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|avg(전체이용거리(m))|\n",
      "+--------------------+\n",
      "|  3970.4106343727362|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "df2.select(mean(col(\"전체이용거리(m)\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c22ee317-4e0b-4df0-81c2-f22beb5cbda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|avg(전체이용시간(분))|\n",
      "+---------------------+\n",
      "|   19.249510036830372|\n",
      "+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2.withColumn(\"전체이용시간(분)\", col(\"전체이용시간(분)\").cast('int')).select(mean(col(\"전체이용시간(분)\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f5b7c9d-e8c5-4b24-abe3-bb6c43910a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import StructType\n",
    "schema = StructType().\\\n",
    "      add('기준_날짜',  StringType(), True ).\\\n",
    "        add('구분코드',  StringType(), True ).\\\n",
    "        add('기준_시간',  StringType(), True ).\\\n",
    "        add('시작_대여소ID',  StringType(), True ).\\\n",
    "        add('시작_대여소명',  StringType(), True ).\\\n",
    "        add('종료_대여소ID',  StringType(), True ).\\\n",
    "        add('종료_대여소명',  StringType(), True ).\\\n",
    "        add('전체건수',  IntegerType(), True ).\\\n",
    "        add('전체이용시간(분)',  IntegerType(), True ).\\\n",
    "        add('전체이용거리(m)' , IntegerType(), True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "357b3595-3c80-48f3-bf6c-9104586fa168",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = spark.read.format(\"csv\").\\\n",
    "        option(\"header\", True).\\\n",
    "        option(\"encoding\", 'cp949').\\\n",
    "        schema(schema).\\\n",
    "        load(\"hdfs:///encore/tpss_bcycl_od_statnhm_202001.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea518123-3bae-49be-9b1a-1ee717e8a391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 기준_날짜: string (nullable = true)\n",
      " |-- 구분코드: string (nullable = true)\n",
      " |-- 기준_시간: string (nullable = true)\n",
      " |-- 시작_대여소ID: string (nullable = true)\n",
      " |-- 시작_대여소명: string (nullable = true)\n",
      " |-- 종료_대여소ID: string (nullable = true)\n",
      " |-- 종료_대여소명: string (nullable = true)\n",
      " |-- 전체건수: integer (nullable = true)\n",
      " |-- 전체이용시간(분): integer (nullable = true)\n",
      " |-- 전체이용거리(m): integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47462ae8-fbf3-4546-8b5d-2ebd084d87c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean, col, max, min, stddev\n",
    "\n",
    "tmp.select( stddev('전체이용시간(분)')).show()\n",
    "\n",
    "\n",
    "tmp.select( mean('전체이용시간(분)')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048fe20-1b80-4cde-a228-5dea91a567eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import coalesce\n",
    "tmp.select(coalesce('전체이용시간(분)')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4c7d1-b8d8-49df-891c-8627c27ce51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the first column that is not null.\n",
    "cDf = spark.createDataFrame([(None, None), (1, None), (None, 2)], (\"a\", \"b\"))\n",
    "cDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dabab270-0254-4b24-a6f3-9d3542b2a78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cDf = spark.createDataFrame([(None, None, None), (None, 1, None), (None, 2, 6), (6, 3, 4)], (\"a\", \"b\", \"c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "271deb35-fbce-4ce6-94bc-0cc91691054f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|   a|   b|   c|\n",
      "+----+----+----+\n",
      "|NULL|NULL|NULL|\n",
      "|NULL|   1|NULL|\n",
      "|NULL|   2|   6|\n",
      "|   6|   3|   4|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42667203-9a3e-4cf9-ad2b-21a39fbf057f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|(a IS NULL)|\n",
      "+-----------+\n",
      "|       true|\n",
      "|       true|\n",
      "|       true|\n",
      "|      false|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# isnull\n",
    "from pyspark.sql.functions import isnull\n",
    "cDf.select(isnull(\"a\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28038a7f-d154-478c-9f4e-1aacf1acccde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cDf.filter(isnull(\"a\") | isnull(\"b\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6d2efe0-865f-4db5-a5d4-5fe491355723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|null|null|null|\n",
      "+----+----+----+\n",
      "|   3|   1|   2|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, count\n",
    "cDf.agg(*[count(when(isnull(x), x)).\\\n",
    "          alias(\"null\") \n",
    "             for x in cDf.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e36900b-d642-4654-8f1c-e756b74632fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-------+\n",
      "|category|value|new_col|\n",
      "+--------+-----+-------+\n",
      "|       A|   10|    low|\n",
      "|       B|   20|    low|\n",
      "|       C|   30|   high|\n",
      "+--------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "when_test = spark.createDataFrame([(\"A\", 10), (\"B\", 20), (\"C\", 30)], [\"category\", \"value\"])\n",
    "\n",
    "df_new = when_test.withColumn(\"new_col\", when(col(\"value\") > 20, \"high\").otherwise(\"low\"))\n",
    "df_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecc24be-cf80-4125-9429-d00162352924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
